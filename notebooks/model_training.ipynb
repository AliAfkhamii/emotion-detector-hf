{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T17:37:13.858463Z",
     "start_time": "2025-05-07T17:37:13.850463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback)\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import evaluate"
   ],
   "id": "ea66e7596510104c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T17:36:47.206162Z",
     "start_time": "2025-05-07T17:36:47.200752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"distilbert/distilbert-base-uncased\"\n",
    "\n",
    "dataset = load_dataset(\"AliAfkhamii/hf_emotion_generation_texts\")\n",
    "\n",
    "labels = dataset[\"train\"].unique(\"label\")\n",
    "id2label = {id: label for id, label in enumerate(labels)}\n",
    "label2id = {label: id for id, label in id2label.items()}\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,\n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)"
   ],
   "id": "b5ac4a13e2ca8ce5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T17:36:37.408187Z",
     "start_time": "2025-05-07T17:36:37.403577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_accuracy(preds_labels: tuple[np.array, np.array]):\n",
    "\n",
    "    preds, labels = preds_labels\n",
    "\n",
    "    if len(preds.shape) >= 2:\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    return accuracy_metric.compute(predictions=preds, references=labels)"
   ],
   "id": "bcff256d71c73940",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T17:36:26.287781Z",
     "start_time": "2025-05-07T17:36:26.282863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def labels_to_ids(sample):\n",
    "    sample['label'] = label2id[sample['label']]\n",
    "    return sample\n",
    "\n",
    "def tokenize_text(sample):\n",
    "    return tokenizer(sample[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "dataset = dataset['train'].map(labels_to_ids).\\\n",
    "           train_test_split(test_size=0.2, shuffle=True).\\\n",
    "           map(tokenize_text, batched=True, batch_size=1000)"
   ],
   "id": "f28649a8d1733371",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T17:36:04.235608Z",
     "start_time": "2025-05-07T17:36:04.230822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = Path(\"../models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_save_name = \"hf_emotion_detector_text_classifier-distilbert-base-uncased\"\n",
    "model_save_dir = model_path / model_save_name\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_save_dir,\n",
    "    learning_rate=0.0005,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=6,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    use_cpu=False,\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.1,\n",
    "    logging_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    hub_private_repo=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  args=training_args,\n",
    "                  train_dataset=dataset[\"train\"],\n",
    "                  eval_dataset=dataset[\"test\"],\n",
    "                  processing_class=tokenizer,\n",
    "                  compute_metrics=compute_accuracy,\n",
    "                  callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "                  )"
   ],
   "id": "6354e717d8036015",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T17:35:16.058190Z",
     "start_time": "2025-05-07T17:35:16.052135Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "311398794d282b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T17:35:52.614984Z",
     "start_time": "2025-05-07T17:35:52.609829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# you must log in first\n",
    "\n",
    "trainer.push_to_hub(\n",
    "    commit_message=\"push best model to hub\",\n",
    ")"
   ],
   "id": "c631dd814e1f584b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### run the cell below only while you want to edit its script:\n",
   "id": "8fc439c142ae616f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T17:39:53.278719Z",
     "start_time": "2025-05-07T17:39:53.266396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%writefile ../src/models/train_model.py\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback)\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "\n",
    "MODEL_NAME = \"distilbert/distilbert-base-uncased\"\n",
    "\n",
    "dataset = load_dataset(\"AliAfkhamii/hf_emotion_generation_texts\")\n",
    "\n",
    "labels = dataset[\"train\"].unique(\"label\")\n",
    "id2label = {id: label for id, label in enumerate(labels)}\n",
    "label2id = {label: id for id, label in id2label.items()}\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,\n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_accuracy(preds_labels: tuple[np.array, np.array]):\n",
    "\n",
    "    preds, labels = preds_labels\n",
    "\n",
    "    if len(preds.shape) >= 2:\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    return accuracy_metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "\n",
    "def labels_to_ids(sample):\n",
    "    sample['label'] = label2id[sample['label']]\n",
    "    return sample\n",
    "\n",
    "def tokenize_text(sample):\n",
    "    return tokenizer(sample[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "dataset = dataset['train'].map(labels_to_ids).\\\n",
    "           train_test_split(test_size=0.2, shuffle=True).\\\n",
    "           map(tokenize_text, batched=True, batch_size=1000)\n",
    "\n",
    "\n",
    "\n",
    "model_path = Path(\"../models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_save_name = \"hf_emotion_detector_text_classifier-distilbert-base-uncased\"\n",
    "model_save_dir = model_path / model_save_name\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(model_save_dir),\n",
    "    learning_rate=0.0005,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=6,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    use_cpu=False,\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.1,\n",
    "    logging_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    hub_private_repo=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  args=training_args,\n",
    "                  train_dataset=dataset[\"train\"],\n",
    "                  eval_dataset=dataset[\"test\"],\n",
    "                  processing_class=tokenizer,\n",
    "                  compute_metrics=compute_accuracy,\n",
    "                  callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "                  )\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# you must log in first\n",
    "trainer.push_to_hub(\n",
    "    commit_message=\"push best model to hub\",\n",
    ")"
   ],
   "id": "eef0e8be11c28538",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/models/train_model.py\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
